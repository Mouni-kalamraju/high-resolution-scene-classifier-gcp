{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup & Data Initialization"
      ],
      "metadata": {
        "id": "_7yFEa7vBSME"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msMFomNAhCHZ",
        "outputId": "ad32ec73-e42b-4d75-fcfa-0a702ee8ca20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Loading"
      ],
      "metadata": {
        "id": "_Ru_FhcGBW3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/model.h5'\n",
        "CLASS_NAMES = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
        "TEST_FOLDER_PATH = '/content/drive/MyDrive/test_images'\n",
        "\n",
        "# Pass the MobileNetV2 version of preprocess_input\n",
        "model2 = load_model(MODEL_PATH, custom_objects={'preprocess_input': preprocess_input})"
      ],
      "metadata": {
        "id": "20Kok5Z4BYnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimental Inference Methods (Legacy)"
      ],
      "metadata": {
        "id": "KjV5uHhOBh4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LEGACY METHODS (DEPRECATED) ---\n",
        "# NOTE: The following Pyramid methods were explored to improve local feature extraction.\n",
        "# REASON FOR DISCARD: While accurate for specific patches, they introduced a 400% - 600%\n",
        "# increase in latency (O(N) complexity) which is unsuitable for real-time edge deployment.\n",
        "# We maintain this code for research documentation only.\n",
        "\n",
        "def method_2_pyramid(img_path):\n",
        "    original_img = Image.open(img_path).convert('RGB')\n",
        "    target_size = 800\n",
        "    w, h = original_img.size\n",
        "    ratio = target_size / max(w, h)\n",
        "    working_img = original_img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)\n",
        "\n",
        "    votes = []\n",
        "    scales = [1.0, 0.75]\n",
        "    patch_size = 150\n",
        "    stride = 100\n",
        "\n",
        "    for scale in scales:\n",
        "        sw = int(working_img.size[0] * scale)\n",
        "        sh = int(working_img.size[1] * scale)\n",
        "        scaled_img = working_img.resize((sw, sh), Image.Resampling.LANCZOS)\n",
        "\n",
        "        for y in range(0, sh - patch_size + 1, stride):\n",
        "            for x in range(0, sw - patch_size + 1, stride):\n",
        "                patch = scaled_img.crop((x, y, x + patch_size, y + patch_size))\n",
        "                patch_arr = np.array(patch).astype('float32')\n",
        "\n",
        "                patch_arr = np.expand_dims(patch_arr, axis=0)\n",
        "\n",
        "                preds = model2.predict(patch_arr, verbose=0)[0]\n",
        "                idx = np.argmax(preds)\n",
        "                conf = preds[idx]\n",
        "\n",
        "                if conf > 0.45:\n",
        "                    votes.append(CLASS_NAMES[idx])\n",
        "\n",
        "    return Counter(votes).most_common(1)[0][0] if votes else \"Uncertain\"\n",
        "\n",
        "def method_3_weighted_pyramid(img_path):\n",
        "    \"\"\"V2 Update: prioritizes 'certain' patches over 'confused' ones.\"\"\"\n",
        "    original_img = Image.open(img_path).convert('RGB')\n",
        "    target_size = 800\n",
        "    w, h = original_img.size\n",
        "    ratio = target_size / max(w, h)\n",
        "    working_img = original_img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)\n",
        "\n",
        "    # Initialize weights for all classes\n",
        "    weighted_votes = {name: 0.0 for name in CLASS_NAMES}\n",
        "\n",
        "    scales = [1.0, 0.75]\n",
        "    patch_size = 150\n",
        "    stride = 100\n",
        "\n",
        "    for scale in scales:\n",
        "        sw, sh = int(working_img.size[0] * scale), int(working_img.size[1] * scale)\n",
        "        scaled_img = working_img.resize((sw, sh), Image.Resampling.LANCZOS)\n",
        "\n",
        "        for y in range(0, sh - patch_size + 1, stride):\n",
        "            for x in range(0, sw - patch_size + 1, stride):\n",
        "                patch = scaled_img.crop((x, y, x + patch_size, y + patch_size))\n",
        "                patch_arr = np.array(patch).astype('float32')\n",
        "                patch_arr = np.expand_dims(patch_arr, axis=0)\n",
        "\n",
        "                preds = model2.predict(patch_arr, verbose=0)[0]\n",
        "                idx = np.argmax(preds)\n",
        "                conf = preds[idx]\n",
        "\n",
        "                # V2 CORE LOGIC: Square the confidence to give certain patches more 'weight'\n",
        "                # This ensures one 90% forest patch beats two 46% building patches\n",
        "                weighted_votes[CLASS_NAMES[idx]] += (conf ** 2)\n",
        "\n",
        "    return max(weighted_votes, key=weighted_votes.get)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def method_4_edge_preserved_resize(img_path):\n",
        "    \"\"\"\n",
        "    V4 CHAMPION: Smart Downsampling.\n",
        "    Preserves edges while reducing to 150x150 for the Intel CNN.\n",
        "    \"\"\"\n",
        "    # 1. Load image (using cv2 for speed)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # 2. Apply Bilateral Filter (Edge-Preserving Smoothing)\n",
        "    # d=9: neighborhood diameter, sigmaColor/Space=75: color/coordinate influence\n",
        "    smooth = cv2.bilateralFilter(img, d=9, sigmaColor=75, sigmaSpace=75)\n",
        "\n",
        "    # 3. Downsample to 150x150 using INTER_AREA\n",
        "    # This is mathematically better for downsampling than standard linear scaling.\n",
        "    low_res = cv2.resize(smooth, (150, 150), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # 4. Final Sharpening (Unsharp Mask)\n",
        "    # This makes edges 'pop' specifically for the CNN features.\n",
        "    gaussian_blur = cv2.GaussianBlur(low_res, (0, 0), 2.0)\n",
        "    sharpened = cv2.addWeighted(low_res, 1.5, gaussian_blur, -0.5, 0)\n",
        "\n",
        "    # Predict using the specialized Intel model\n",
        "    arr = np.expand_dims(sharpened.astype('float32'), axis=0)\n",
        "    preds = model2.predict(arr, verbose=0)[0]\n",
        "\n",
        "    return CLASS_NAMES[np.argmax(preds)]\n"
      ],
      "metadata": {
        "id": "5OKAiUT5Bs55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimized Inference Engines"
      ],
      "metadata": {
        "id": "MRwoqRbCBxNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- THE WORKING METHODS ---\n",
        "\n",
        "def method_1_baseline(img_path):\n",
        "    img = Image.open(img_path).convert('RGB').resize((150, 150))\n",
        "    arr = np.array(img).astype('float32')\n",
        "    preds = model2.predict(np.expand_dims(arr, axis=0), verbose=0)[0]\n",
        "    return CLASS_NAMES[np.argmax(preds)]\n",
        "\n",
        "def method_5_fast_ensemble(img_path):\n",
        "    \"\"\"\n",
        "    V5 CHAMPION: Optimized for production.\n",
        "    Loads image once, branches into two streams, and soft-votes.\n",
        "    \"\"\"\n",
        "    # Load once\n",
        "    img_bgr = cv2.imread(img_path)\n",
        "    if img_bgr is None: return \"Error\"\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # STREAM 1: Baseline (Global Context)\n",
        "    low_res_raw = cv2.resize(img_rgb, (150, 150), interpolation=cv2.INTER_AREA)\n",
        "    prob_baseline = model2.predict(np.expand_dims(low_res_raw.astype('float32'), 0), verbose=0)[0]\n",
        "\n",
        "    # STREAM 2: Smart (Local Features)\n",
        "    # Re-using your logic but without re-reading from disk\n",
        "    mid_res = cv2.resize(img_rgb, (300, 300), interpolation=cv2.INTER_AREA)\n",
        "    smooth = cv2.bilateralFilter(mid_res, d=5, sigmaColor=50, sigmaSpace=50)\n",
        "\n",
        "    lab = cv2.cvtColor(smooth, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    cl = clahe.apply(l)\n",
        "    enhanced = cv2.cvtColor(cv2.merge((cl, a, b)), cv2.COLOR_LAB2RGB)\n",
        "\n",
        "    low_res_smart = cv2.resize(enhanced, (150, 150), interpolation=cv2.INTER_AREA)\n",
        "    prob_smart = model2.predict(np.expand_dims(low_res_smart.astype('float32'), 0), verbose=0)[0]\n",
        "\n",
        "    # FINAL VOTE\n",
        "    final_probs = (prob_baseline + prob_smart) / 2\n",
        "    return CLASS_NAMES[np.argmax(final_probs)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jvGIelP8hRm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Benchmarking"
      ],
      "metadata": {
        "id": "HiCfrEc4B7pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing all methods"
      ],
      "metadata": {
        "id": "_Egt0WFXCMUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for filename in sorted(os.listdir(TEST_FOLDER_PATH)):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        path = os.path.join(TEST_FOLDER_PATH, filename)\n",
        "\n",
        "        # --- Baseline (Standard Resize) ---\n",
        "        start_b = time.time()\n",
        "        res_b = method_1_baseline(path)\n",
        "        time_b = time.time() - start_b\n",
        "\n",
        "         # --- Test CNN (Pyramid Model) ---\n",
        "        start_pyramid = time.time()\n",
        "        res_pyramid = method_2_pyramid(path)\n",
        "        time_pyramid = time.time() - start_pyramid\n",
        "\n",
        "        # --- Test CNN (Specialized Model) ---\n",
        "        start_Wcnn = time.time()\n",
        "        res_Wcnn = method_3_weighted_pyramid(path)\n",
        "        time_Wcnn = time.time() - start_Wcnn\n",
        "\n",
        "        # --- V4 (Smart Edge-Preserved Downsample) ---\n",
        "        start_v4 = time.time()\n",
        "        res_v4 = method_4_edge_preserved_resize(path)\n",
        "        time_v4 = time.time() - start_v4\n",
        "\n",
        "        # --- V5 (Smart Ensemble) ---\n",
        "        start_v5 = time.time()\n",
        "        res_v5 = method_5_fast_ensemble(path)\n",
        "        # FIX: Corrected time calculation to use start_v5\n",
        "        time_v5 = time.time() - start_v5\n",
        "\n",
        "        results.append({\n",
        "            \"File\": filename,\n",
        "            \"Baseline (Std)\": res_b,\n",
        "            \"Pyramid\": res_pyramid,\n",
        "            \"Weighted Pyramid\": res_Wcnn,\n",
        "            \"Smart (V4)\": res_v4,\n",
        "            \"Smart (V5)\": res_v5,\n",
        "            \"Baseline Time\": f\"{time_b:.3f}s\",\n",
        "            \"Pyramid Time\": f\"{time_pyramid:.3f}s\",\n",
        "           \"Weighted Time\": f\"{time_Wcnn:.3f}s\",\n",
        "            \"Smart v4 Time\": f\"{time_v4:.3f}s\",\n",
        "             \"Smart Time\": f\"{time_v5:.3f}s\"\n",
        "        })\n",
        "\n",
        "df_final = pd.DataFrame(results)\n",
        "print(df_final.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W4RZ7qlh4jg",
        "outputId": "66e0dda5-4718-49e4-90e5-d605c63ec0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    File Baseline (Std)   Pyramid Weighted Pyramid Smart (V4) Smart (V5) Baseline Time Pyramid Time Weighted Time Smart v4 Time Smart Time\n",
            "           building1.jpg      buildings buildings        buildings  buildings  buildings        3.636s       3.072s        4.202s        2.788s     0.832s\n",
            "           building2.jpg      buildings buildings        buildings  buildings  buildings        1.177s       3.858s        4.588s        3.589s     0.962s\n",
            "           building3.jpg      buildings buildings        buildings  buildings  buildings        1.346s       3.906s        4.896s        5.437s     1.603s\n",
            "           building4.jpg      buildings buildings        buildings  buildings  buildings        0.933s       4.728s        3.599s        2.376s     0.605s\n",
            "           building5.jpg      buildings buildings        buildings  buildings  buildings        0.877s       4.416s        3.184s        2.461s     0.774s\n",
            "           building6.jpg      buildings buildings        buildings  buildings  buildings        0.730s       2.747s        3.911s        0.769s     0.398s\n",
            "        building_sea.jpg            sea       sea              sea        sea        sea        1.170s       3.391s        3.635s        5.005s     0.993s\n",
            "       building_sea2.jpg            sea       sea              sea        sea        sea        1.076s       3.362s        3.583s        3.990s     0.871s\n",
            "              forest.jpg         forest    forest           forest     forest     forest        0.974s       4.132s        4.583s        2.009s     0.599s\n",
            "             forest2.jpg         forest    forest           forest     forest     forest        0.897s       3.738s        3.583s        2.796s     1.107s\n",
            "             forest3.jpg         forest    forest           forest     forest     forest        1.308s       3.492s        3.449s        4.422s     1.830s\n",
            "             forest4.jpg         forest    forest           forest     forest     forest        1.277s       3.494s        3.538s        5.019s     1.392s\n",
            "             forest5.jpg         forest    forest           forest     forest     forest        1.142s       2.964s        3.084s        0.977s     0.459s\n",
            "             forest6.jpg         forest    forest           forest     forest     forest        0.907s       4.037s        3.023s        1.643s     0.568s\n",
            "             glacier.jpg       mountain  mountain         mountain   mountain   mountain        1.335s       4.876s        3.809s        5.462s     2.129s\n",
            "            glacier2.jpg        glacier   glacier          glacier    glacier    glacier        1.087s       3.137s        3.126s        2.392s     0.549s\n",
            "            glacier3.jpg       mountain   glacier          glacier    glacier   mountain        0.617s       4.248s        2.986s        1.583s     0.466s\n",
            "            glacier4.jpg        glacier  mountain         mountain    glacier    glacier        0.851s       3.526s        4.088s        2.680s     0.751s\n",
            "            glacier5.jpg        glacier   glacier          glacier    glacier    glacier        0.727s       3.167s        4.228s        1.866s     0.579s\n",
            "            mountain.jpg            sea  mountain         mountain        sea        sea        1.092s       3.355s        3.756s        3.292s     0.991s\n",
            "           mountain2.jpg       mountain  mountain         mountain   mountain   mountain        0.834s       3.132s        3.079s        2.124s     0.918s\n",
            "           mountain3.jpg       mountain  mountain         mountain   mountain   mountain        1.399s       3.435s        3.501s        3.992s     1.539s\n",
            "           mountain4.jpg       mountain  mountain         mountain   mountain   mountain        0.960s       3.290s        3.258s        2.736s     1.143s\n",
            "           mountain5.jpg       mountain  mountain         mountain   mountain   mountain        2.135s       3.963s        3.919s        7.133s     1.878s\n",
            "     mountain_forest.jpg       mountain  mountain         mountain   mountain   mountain        1.050s       4.267s        5.593s        2.924s     1.245s\n",
            " mountain_sea_forest.png        glacier  mountain         mountain    glacier    glacier        0.669s       2.192s        2.024s        0.252s     0.291s\n",
            "mountain_sea_forest2.jpg       mountain  mountain         mountain   mountain   mountain        1.189s       3.748s        3.481s        2.539s     0.875s\n",
            "mountain_sea_forest2.png       mountain  mountain         mountain   mountain   mountain        0.596s       3.227s        2.175s        0.225s     0.222s\n",
            "mountain_sea_forest3.jpg        glacier    forest           forest    glacier   mountain        0.808s       3.880s        5.097s        2.074s     0.617s\n",
            "                 sea.jpg            sea       sea              sea        sea        sea        0.804s       3.185s        3.149s        2.878s     0.797s\n",
            "                sea2.jpg            sea       sea              sea        sea        sea        1.324s       3.319s        3.569s        3.801s     1.366s\n",
            "                sea3.jpg            sea       sea              sea        sea        sea        0.578s       5.031s        5.910s        1.186s     0.461s\n",
            "                sea4.jpg            sea       sea              sea        sea        sea        1.219s       3.614s        3.647s        4.749s     1.382s\n",
            "                sea5.jpg            sea       sea              sea        sea        sea        1.159s       3.714s        3.772s        5.358s     1.309s\n",
            "                sea6.jpg            sea       sea              sea        sea        sea        0.747s       4.067s        4.283s        2.370s     0.672s\n",
            "              street.jpg         street buildings        buildings     street  buildings        0.824s       3.758s        3.845s        2.150s     0.861s\n",
            "             street2.jpg         street buildings        buildings     street     street        0.884s       3.571s        3.241s        1.292s     0.447s\n",
            "             street3.jpg         street buildings        buildings     street     street        1.291s       4.791s        3.685s        3.192s     1.289s\n",
            "             street4.jpg       mountain  mountain         mountain     street   mountain        0.588s       4.283s        3.133s        0.579s     0.285s\n",
            "             street5.jpg         street  mountain           street     street     street        0.966s       3.502s        4.683s        3.041s     0.932s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "341e1c58",
        "outputId": "6627275d-5e9e-4ad5-afe3-bb8aa2a18e24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output_csv_path = 'prediction_results.csv'\n",
        "df_final.to_csv(output_csv_path, index=False)\n",
        "print(f\"Results saved to {output_csv_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to prediction_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Master Benchmark"
      ],
      "metadata": {
        "id": "MXt646xwCQe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MASTER BENCHMARK ---\n",
        "results = []\n",
        "print(\"Starting Final Benchmark...\")\n",
        "\n",
        "for filename in sorted(os.listdir(TEST_FOLDER_PATH)):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        path = os.path.join(TEST_FOLDER_PATH, filename)\n",
        "\n",
        "        # 1. Baseline\n",
        "        s = time.time()\n",
        "        res_b = method_1_baseline(path)\n",
        "        t_b = time.time() - s\n",
        "\n",
        "        # 2. Smart Champion (V5)\n",
        "        s = time.time()\n",
        "        res_v5 = method_5_fast_ensemble(path)\n",
        "        t_v5 = time.time() - s\n",
        "\n",
        "        # We keep Pyramid/Weighted as 'Historical Data' if you need it,\n",
        "        # but for the final table, focus on the 'Evolution'\n",
        "        results.append({\n",
        "            \"File\": filename,\n",
        "            \"Baseline\": res_b,\n",
        "            \"Smart V5\": res_v5,\n",
        "            \"B-Time\": f\"{t_b:.3f}s\",\n",
        "            \"V5-Time\": f\"{t_v5:.3f}s\",\n",
        "        })\n",
        "\n",
        "df_final = pd.DataFrame(results)\n",
        "print(df_final.to_string(index=False))"
      ],
      "metadata": {
        "id": "SlmvChWty7UF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}